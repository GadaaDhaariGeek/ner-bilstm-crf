{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18460\\1203629992.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPACKAGE_ROOT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_rows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_columns\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "PACKAGE_ROOT = os.path.dirname(os.path.abspath(\"\"))\n",
    "# print(PACKAGE_ROOT)\n",
    "sys.path.insert(0, PACKAGE_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from commons import constants as C\n",
    "from feature_engineering import generate_simple_word_features\n",
    "\n",
    "# train data\n",
    "train_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\train.csv\")\n",
    "\n",
    "# validation data\n",
    "valid_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\valid.csv\")\n",
    "\n",
    "# test data\n",
    "test_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "agg_df = train_df.groupby([\"sentence_id\"]).agg( word_list=pd.NamedAgg(column=\"token\", aggfunc=list), \n",
    "                                      tag_list=pd.NamedAgg(column=\"tag\", aggfunc=list) ).reset_index()\n",
    "X_train = list(agg_df.word_list.values)\n",
    "y_train = list(agg_df.tag_list.values)\n",
    "\n",
    "# validation data\n",
    "agg_df = valid_df.groupby([\"sentence_id\"]).agg( word_list=pd.NamedAgg(column=\"token\", aggfunc=list), \n",
    "                                      tag_list=pd.NamedAgg(column=\"tag\", aggfunc=list) ).reset_index()\n",
    "X_valid = list(agg_df.word_list.values)\n",
    "y_valid = list(agg_df.tag_list.values)\n",
    "\n",
    "# test data\n",
    "agg_df = test_df.groupby([\"sentence_id\"]).agg( word_list=pd.NamedAgg(column=\"token\", aggfunc=list), \n",
    "                                      tag_list=pd.NamedAgg(column=\"tag\", aggfunc=list) ).reset_index()\n",
    "X_test = list(agg_df.word_list.values)\n",
    "y_test = list(agg_df.tag_list.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = train_df[\"token\"].values.tolist()\n",
    "words = [generate_simple_word_features(word) for word in words]\n",
    "tags = train_df[\"tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6}\n"
     ]
    }
   ],
   "source": [
    "# List down all the unique length of sentences and words. As expected, set of all the unqiue lengths of word is singleton.\n",
    "# n_sentence = set()\n",
    "# n_word = set()\n",
    "# for sentence in X_train_wf:\n",
    "#     n_sentence.add(len(sentence))\n",
    "#     for word in sentence:\n",
    "#         n_word.add(len(word))\n",
    "#         # print(len(sentence), len(word))\n",
    "# # print(n_sentence)\n",
    "# print(n_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharm\\anaconda3\\envs\\nlp_assignment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sharm\\anaconda3\\envs\\nlp_assignment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "B-AerospaceManufacturer       0.00      0.00      0.00       216\n",
      "  B-AnatomicalStructure       0.00      0.00      0.00       388\n",
      "              B-ArtWork       0.00      0.00      0.00       199\n",
      "               B-Artist       0.09      0.00      0.00      3712\n",
      "              B-Athlete       0.00      0.00      0.00      1793\n",
      "      B-CarManufacturer       0.00      0.00      0.00       249\n",
      "               B-Cleric       0.00      0.00      0.00       299\n",
      "             B-Clothing       0.00      0.00      0.00       197\n",
      "              B-Disease       0.00      0.00      0.00       372\n",
      "                B-Drink       0.00      0.00      0.00       212\n",
      "             B-Facility       0.02      0.00      0.00      1053\n",
      "                 B-Food       0.00      0.00      0.00       362\n",
      "      B-HumanSettlement       0.07      0.00      0.00      2617\n",
      "     B-MedicalProcedure       0.00      0.00      0.00       242\n",
      "   B-Medication/Vaccine       0.33      0.00      0.01       355\n",
      "           B-MusicalGRP       0.06      0.00      0.01       825\n",
      "          B-MusicalWork       0.00      0.00      0.00       953\n",
      "                  B-ORG       0.17      0.00      0.00      1480\n",
      "             B-OtherLOC       0.08      0.00      0.01       291\n",
      "             B-OtherPER       0.00      0.00      0.00      1777\n",
      "            B-OtherPROD       0.00      0.00      0.00       786\n",
      "           B-Politician       0.00      0.00      0.00      1050\n",
      "          B-PrivateCorp       0.00      0.00      0.00       201\n",
      "           B-PublicCorp       0.00      0.00      0.00       437\n",
      "            B-Scientist       0.00      0.00      0.00       318\n",
      "             B-Software       0.00      0.00      0.00       593\n",
      "            B-SportsGRP       0.75      0.00      0.01       816\n",
      "        B-SportsManager       0.00      0.00      0.00       344\n",
      "              B-Station       0.00      0.00      0.00       392\n",
      "              B-Symptom       0.10      0.02      0.03       202\n",
      "              B-Vehicle       0.00      0.00      0.00       377\n",
      "           B-VisualWork       0.00      0.00      0.00      1266\n",
      "          B-WrittenWork       0.00      0.00      0.00      1073\n",
      "I-AerospaceManufacturer       0.00      0.00      0.00       178\n",
      "  I-AnatomicalStructure       0.00      0.00      0.00       148\n",
      "              I-ArtWork       0.00      0.00      0.00       520\n",
      "               I-Artist       0.03      0.00      0.00      3842\n",
      "              I-Athlete       0.09      0.00      0.01      1812\n",
      "      I-CarManufacturer       0.00      0.00      0.00       102\n",
      "               I-Cleric       0.00      0.00      0.00       395\n",
      "             I-Clothing       0.00      0.00      0.00        87\n",
      "              I-Disease       0.00      0.00      0.00       283\n",
      "                I-Drink       0.00      0.00      0.00        84\n",
      "             I-Facility       0.00      0.00      0.00      1578\n",
      "                 I-Food       0.00      0.00      0.00       112\n",
      "      I-HumanSettlement       0.00      0.00      0.00      1239\n",
      "     I-MedicalProcedure       0.00      0.00      0.00       150\n",
      "   I-Medication/Vaccine       0.00      0.00      0.00        89\n",
      "           I-MusicalGRP       0.00      0.00      0.00       996\n",
      "          I-MusicalWork       0.00      0.00      0.00      1813\n",
      "                  I-ORG       0.00      0.00      0.00      2193\n",
      "             I-OtherLOC       0.00      0.00      0.00       595\n",
      "             I-OtherPER       0.03      0.00      0.00      2261\n",
      "            I-OtherPROD       0.00      0.00      0.00       571\n",
      "           I-Politician       0.05      0.00      0.00      1432\n",
      "          I-PrivateCorp       0.00      0.00      0.00       170\n",
      "           I-PublicCorp       0.00      0.00      0.00       298\n",
      "            I-Scientist       0.00      0.00      0.00       391\n",
      "             I-Software       0.00      0.00      0.00       613\n",
      "            I-SportsGRP       0.00      0.00      0.00      1125\n",
      "        I-SportsManager       0.00      0.00      0.00       358\n",
      "              I-Station       0.00      0.00      0.00       606\n",
      "              I-Symptom       0.00      0.00      0.00       108\n",
      "              I-Vehicle       0.00      0.00      0.00       305\n",
      "           I-VisualWork       0.00      0.00      0.00      2281\n",
      "          I-WrittenWork       0.00      0.00      0.00      1852\n",
      "                      O       0.79      1.00      0.88    198961\n",
      "                      _       0.00      0.00      0.00        16\n",
      "\n",
      "               accuracy                           0.79    253011\n",
      "              macro avg       0.04      0.02      0.01    253011\n",
      "           weighted avg       0.63      0.79      0.69    253011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharm\\anaconda3\\envs\\nlp_assignment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
    "                         X=words, y=tags, cv=5)\n",
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest with some more features context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "PACKAGE_ROOT = os.path.dirname(os.path.abspath(\"\"))\n",
    "# print(PACKAGE_ROOT)\n",
    "sys.path.insert(0, PACKAGE_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from commons import constants as C\n",
    "from feature_engineering import generate_simple_word_features\n",
    "from feature_engineering import FeatureTransformer\n",
    "\n",
    "# train data\n",
    "train_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\train.csv\")\n",
    "\n",
    "# validation data\n",
    "valid_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\valid.csv\")\n",
    "\n",
    "# test data\n",
    "test_df = pd.read_csv(r\"C:\\Users\\sharm\\Documents\\nlp_assignment\\ner_impls\\data\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.memory_tagger import MemoryTagger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "memory_tagger = MemoryTagger()\n",
    "tag_encoder = LabelEncoder()\n",
    "# all the words as a single list\n",
    "words = train_df[\"token\"].values.tolist()\n",
    "# all the tags as single list \n",
    "tags = train_df[\"tag\"].values.tolist()\n",
    "# fit memory tagger\n",
    "memory_tagger.fit([words], [tags])\n",
    "# encode tags\n",
    "tag_encoder.fit(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253011 253011\n"
     ]
    }
   ],
   "source": [
    "print(len(words), len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ft = FeatureTransformer()\n",
    "ft.fit(train_df, None)\n",
    "train_df_transformed = ft.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  0,  6,  0,  1,  3, 52, 66])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=20, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=20, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, n_jobs=-1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20, n_jobs=-1)\n",
    "rfc.fit(train_df_transformed, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'I-Athlete' 'O' ... 'O' 'O' 'O']\n",
      "13323\n"
     ]
    }
   ],
   "source": [
    "X_valid = ft.transform(valid_df)\n",
    "y_valid = valid_df[\"tag\"].values.tolist()\n",
    "y_pred = rfc.predict(X_valid)\n",
    "print(y_pred)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to MLB for calculating metrics report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "yv = mlb.fit_transform([y_valid])\n",
    "yp = mlb.transform([y_pred])\n",
    "# yv\n",
    "# mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'I-Athlete', 'O', ..., 'O', 'O', 'O'], dtype='<U23')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-AerospaceManufacturer</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-AnatomicalStructure</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ArtWork</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Artist</th>\n",
       "      <td>0.462766</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Athlete</th>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-CarManufacturer</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Cleric</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Clothing</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Disease</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Drink</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Facility</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Food</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-HumanSettlement</th>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.564593</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MedicalProcedure</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Medication/Vaccine</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MusicalGRP</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MusicalWork</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-OtherLOC</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-OtherPER</th>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-OtherPROD</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Politician</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PrivateCorp</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PublicCorp</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Scientist</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Software</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-SportsGRP</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-SportsManager</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Station</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Symptom</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Vehicle</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-VisualWork</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-WrittenWork</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-AerospaceManufacturer</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-AnatomicalStructure</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ArtWork</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Artist</th>\n",
       "      <td>0.537736</td>\n",
       "      <td>0.262673</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Athlete</th>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-CarManufacturer</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Cleric</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Clothing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Disease</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Drink</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Facility</th>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Food</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-HumanSettlement</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MedicalProcedure</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Medication/Vaccine</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MusicalGRP</th>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MusicalWork</th>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-OtherLOC</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-OtherPER</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-OtherPROD</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Politician</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PrivateCorp</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PublicCorp</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Scientist</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Software</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-SportsGRP</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-SportsManager</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Station</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Symptom</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Vehicle</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-VisualWork</th>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-WrittenWork</th>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.662069</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.882418</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.927606</td>\n",
       "      <td>10570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.832095</td>\n",
       "      <td>0.832095</td>\n",
       "      <td>0.832095</td>\n",
       "      <td>0.832095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.440477</td>\n",
       "      <td>0.265136</td>\n",
       "      <td>0.316451</td>\n",
       "      <td>13323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.790961</td>\n",
       "      <td>0.832095</td>\n",
       "      <td>0.803539</td>\n",
       "      <td>13323.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall  f1-score       support\n",
       "B-AerospaceManufacturer   0.818182  0.900000  0.857143     10.000000\n",
       "B-AnatomicalStructure     0.750000  0.529412  0.620690     17.000000\n",
       "B-ArtWork                 0.500000  0.153846  0.235294     13.000000\n",
       "B-Artist                  0.462766  0.410377  0.435000    212.000000\n",
       "B-Athlete                 0.369231  0.303797  0.333333     79.000000\n",
       "B-CarManufacturer         0.500000  0.461538  0.480000     13.000000\n",
       "B-Cleric                  0.444444  0.266667  0.333333     15.000000\n",
       "B-Clothing                0.250000  0.100000  0.142857     10.000000\n",
       "B-Disease                 0.500000  0.444444  0.470588     18.000000\n",
       "B-Drink                   1.000000  0.454545  0.625000     11.000000\n",
       "B-Facility                0.461538  0.230769  0.307692     52.000000\n",
       "B-Food                    0.750000  0.157895  0.260870     19.000000\n",
       "B-HumanSettlement         0.590000  0.541284  0.564593    109.000000\n",
       "B-MedicalProcedure        0.333333  0.153846  0.210526     13.000000\n",
       "B-Medication/Vaccine      0.571429  0.222222  0.320000     18.000000\n",
       "B-MusicalGRP              0.200000  0.081081  0.115385     37.000000\n",
       "B-MusicalWork             0.090909  0.016393  0.027778     61.000000\n",
       "B-ORG                     0.516667  0.397436  0.449275     78.000000\n",
       "B-OtherLOC                0.500000  0.187500  0.272727     16.000000\n",
       "B-OtherPER                0.328125  0.230769  0.270968     91.000000\n",
       "B-OtherPROD               0.636364  0.285714  0.394366     49.000000\n",
       "B-Politician              0.440000  0.207547  0.282051     53.000000\n",
       "B-PrivateCorp             0.857143  0.545455  0.666667     11.000000\n",
       "B-PublicCorp              0.428571  0.107143  0.171429     28.000000\n",
       "B-Scientist               0.000000  0.000000  0.000000     15.000000\n",
       "B-Software                0.444444  0.307692  0.363636     26.000000\n",
       "B-SportsGRP               0.566667  0.414634  0.478873     41.000000\n",
       "B-SportsManager           0.100000  0.062500  0.076923     16.000000\n",
       "B-Station                 0.272727  0.150000  0.193548     20.000000\n",
       "B-Symptom                 0.750000  0.600000  0.666667     10.000000\n",
       "B-Vehicle                 0.750000  0.300000  0.428571     20.000000\n",
       "B-VisualWork              0.000000  0.000000  0.000000     61.000000\n",
       "B-WrittenWork             0.695652  0.296296  0.415584     54.000000\n",
       "I-AerospaceManufacturer   0.500000  0.428571  0.461538      7.000000\n",
       "I-AnatomicalStructure     0.000000  0.000000  0.000000      4.000000\n",
       "I-ArtWork                 0.090909  0.045455  0.060606     22.000000\n",
       "I-Artist                  0.537736  0.262673  0.352941    217.000000\n",
       "I-Athlete                 0.340000  0.217949  0.265625     78.000000\n",
       "I-CarManufacturer         0.166667  0.166667  0.166667      6.000000\n",
       "I-Cleric                  0.333333  0.250000  0.285714     16.000000\n",
       "I-Clothing                0.000000  0.000000  0.000000      2.000000\n",
       "I-Disease                 0.545455  0.272727  0.363636     22.000000\n",
       "I-Drink                   0.000000  0.000000  0.000000      2.000000\n",
       "I-Facility                0.418605  0.281250  0.336449     64.000000\n",
       "I-Food                    0.000000  0.000000  0.000000      9.000000\n",
       "I-HumanSettlement         0.772727  0.708333  0.739130     72.000000\n",
       "I-MedicalProcedure        0.400000  0.222222  0.285714      9.000000\n",
       "I-Medication/Vaccine      1.000000  0.166667  0.285714      6.000000\n",
       "I-MusicalGRP              0.360000  0.195652  0.253521     46.000000\n",
       "I-MusicalWork             0.276596  0.120370  0.167742    108.000000\n",
       "I-ORG                     0.486111  0.324074  0.388889    108.000000\n",
       "I-OtherLOC                0.666667  0.437500  0.528302     32.000000\n",
       "I-OtherPER                0.388889  0.172131  0.238636    122.000000\n",
       "I-OtherPROD               0.500000  0.095238  0.160000     42.000000\n",
       "I-Politician              0.255814  0.183333  0.213592     60.000000\n",
       "I-PrivateCorp             0.600000  0.300000  0.400000     10.000000\n",
       "I-PublicCorp              0.500000  0.080000  0.137931     25.000000\n",
       "I-Scientist               0.000000  0.000000  0.000000     16.000000\n",
       "I-Software                0.111111  0.037037  0.055556     27.000000\n",
       "I-SportsGRP               0.555556  0.543478  0.549451     46.000000\n",
       "I-SportsManager           0.250000  0.058824  0.095238     17.000000\n",
       "I-Station                 0.533333  0.296296  0.380952     27.000000\n",
       "I-Symptom                 0.666667  0.666667  0.666667      3.000000\n",
       "I-Vehicle                 0.500000  0.150000  0.230769     20.000000\n",
       "I-VisualWork              0.122449  0.049180  0.070175    122.000000\n",
       "I-WrittenWork             0.872727  0.533333  0.662069     90.000000\n",
       "O                         0.882418  0.977673  0.927606  10570.000000\n",
       "accuracy                  0.832095  0.832095  0.832095      0.832095\n",
       "macro avg                 0.440477  0.265136  0.316451  13323.000000\n",
       "weighted avg              0.790961  0.832095  0.803539  13323.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true=y_valid, y_pred=y_pred, output_dict=True)#, target_names=mlb.classes_)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
